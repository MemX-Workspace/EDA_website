<template>
    <div class="lecture-preview">
        <div class="lecture-details">
            <h3>Lecture III</h3>
            <p><strong>Friday, June 21, 15:10-17:00</strong></p>
            <h4>Knowledge-Enhanced LLMs with Retrieval-Augmented Generation</h4>
            <div class="row">
                <div class="speaker-details" style="width: 75%;margin-left: 15px;">
                    <p><strong>Mr. Hailin Xu</strong></p>
                    <p style="font-size: 0.8rem; margin-bottom: 0;">Ph.D. student at the School of Computer Science,
                        Fudan University.</p>
                    <p style="font-size: 0.8rem; margin-bottom: 0;">Experienced AI researcher on the applications of
                        LLMs.</p>
                </div>
                <img src="img/photos/Hailin_Xu.png" alt="Mr. Hailin Xu" class="speaker-photo"
                    style="width: 100px; height: 100px;object-fit: cover;">
            </div>
            <div class="lecture-description">
                <p style="font-size: 1.0rem;margin-top: 10px;">
                    Large language models (LLMs) have demonstrated powerful capabilities in language understanding and
                    generation. Combining LLMs with domain knowledge is a very promising application direction. In
                    particular, Retrieval-Augmented Generation (RAG) integrates LLMs with external knowledge bases,
                    making it especially suitable for solving knowledge-intensive tasks. This technology dynamically
                    retrieves information from large external knowledge sources and integrates this information into the
                    generation process of the LLMs, thereby improving the relevance and accuracy of the generated
                    content. This Lecture will introduce the basic principles and key technologies of
                    retrieval-augmented generation, and explore its application potential.
                </p>
            </div>
        </div>
    </div>
</template>
